<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="TARGO: Benchmarking Target-driven Object Grasping under Occlusions">
  <meta property="og:title" content="TARGO"/>
  <meta property="og:description" content="TARGO: Benchmarking Target-driven Object Grasping under Occlusions"/>
  <meta property="og:url" content="https://targo-benchmark.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/reference.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="TARGO: Benchmarking Target-driven Object Grasping under Occlusions">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TARGO: Benchmarking Target-driven Object Grasping under Occlusions</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>
  <script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TARGO: Benchmarking Target-driven Object Grasping under Occlusions</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yan-xia.github.io" target="_blank">Yan Xia</a><sup>1,4*</sup>,
              </span>
              <span class="author-block">
                <a href="https://randing2000.github.io" target="_blank">Ran Ding</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=pcCR2lUAAAAJ" target="_blank">Ziyuan Qin</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.robots.ox.ac.uk/~guanqi" target="_blank">Guanqi Zhan</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.ox.ac.uk/people/kaichen.zhou" target="_blank">Kaichen Zhou</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=KOTg0mQAAAAJ&hl" target="_blank">Long Yang</a><sup>2</sup>,
              </span><br>
              <span class="author-block">
                <a href="https://zsdonghao.github.io" target="_blank">Hao Dong</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">Daniel Cremers</a><sup>1,4</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Technical University of Munich,</span>&ensp;
                    <span class="author-block"><sup>2</sup>CFCS, School of CS, Peking University,</span><br>
                    <span class="author-block"><sup>3</sup>University of Oxford,</span>&ensp;
                    <span class="author-block"><sup>4</sup>Munich Center for Machine Learning (MCML)</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2407.06168" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="TODO" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                    <!-- Dataset Link. -->
                    <span class="link-block">
                      <a href="https://datasets.cvg.cit.tum.de/targo-benchmark/syn_train.tar.gz"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          
                          <!-- <i class="fa-solid fa-file-code"></i> -->
                            <!-- <i class="fa-solid fa-database"></i> -->
                            <i class="fas fa-download"></i>
                        </span>
                        <span>Dataset</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/TARGO-benchmark/TARGO" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                
                  <!-- Video Link. -->
                  <span class="link-block">
                    <a href="https://youtube.com/playlist?list=PLoiJ-CQYChoI1GEpxmASlOQfIyJP6-_a4&si=ltEs5OkwfRKkUF3E"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in predicting 6D grasp poses from a single depth image have led to promising performance in robotic grasping. However, previous grasping models face challenges in cluttered environments where nearby objects impact the target object's grasp. In this paper, we first establish a new benchmark dataset for TARget-driven Grasping under Occlusions, named <strong>TARGO</strong>. We make the following contributions:
          </p>
          <p>
            <strong>1)</strong> We are the first to study the occlusion level in target-driven grasping.
          </p>
          <p>
            <strong>2)</strong> We set up an evaluation benchmark consisting of large-scale synthetic data and part of real-world data, and we evaluated five grasp models and found that even the current SOTA model suffers when the occlusion level increases, leaving grasping under occlusion still a challenge.
          </p>
          <p>
            <strong>3)</strong> We also generate a large-scale training dataset via a scalable pipeline, which can be used to boost the performance of grasping under occlusion and generalized to the real world.
          </p>
          <p>
            <strong>4)</strong> We further propose a transformer-based grasping model involving a shape completion module, termed <strong>TARGO-Net</strong>, which performs most robustly as occlusion increases.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TARGO Dataset</h2>
        <img src="./static/images/data_overview.svg" alt="Data Overview" />
         <!-- <figure style="text-align: center;">
          <img src="./static/images/data_overview.svg" alt="Data Overview"/>
          <figcaption>TARGO-Synthetic training, TARGO-Synthetic test, TARGO-Real samples in various occlusion levels.</figcaption>
        </figure> -->
        <div class="content has-text-justified">
          <p>
            We present a novel dataset, <strong>TARGO</strong>, to thoroughly investigate the occlusion challenge in robotic grasping. The synthetic dataset can be used to train and evaluate the target-driven grasping models under various occlusion levels, and the real-world one can be tested for zero-shot transfer to evaluate grasping performance in practice.
          </p>
          <p>
            The <strong>TARGO-synthetic training and test</strong> datasets are generated using the physical simulator PyBullet, which samples collision-free grasps in a $30 \times 30 \times 30 \mathrm{~cm}^3$ tabletop workspace. We generated the packed scenes using 114 training and 16 test objects provided by VGN. In each <em>cluttered scene</em>, an object is selected as the target object, inducing a <em>single scene</em>, where only the target is on the table and all other occluders are removed. Given the single scene, <em>occlusion level</em> can be calculated (the percentage of the target object occluded by the occluders). Sampling grasps from single scenes helps grasp prediction, and the occlusion level can be used to evaluate the model's robustness to occlusion. The TARGO-Synthetic training dataset is available for download <a href="https://datasets.cvg.cit.tum.de/targo-benchmark/syn_train.tar.gz">here</a>.
          </p>
          <p>
            The <strong>TARGO-Real dataset</strong> includes object models and object poses in scenes provided by DexYCB. Using the real-world observations, we created the corresponding scenes in PyBullet to evaluate various baseline methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-12">
        <h2 class="title">Cluttered Scene vs. Single Scene</h2>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-5">
        <h5 class="">Cluttered Scene</h5>
        <img src="./static/images/cluttered_scene_rw.png" alt="cluttered scene" />
      </div>
      <div class="column is-5">
        <h5 class="">Single Scene</h5>
          <img src="./static/images/single_scene_rw.png" alt="single scene" />
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TARGO-Synthetic Dataset Folder Contents</h2>
        <div class="content has-text-justified">
          <p>
            The <a href="https://datasets.cvg.cit.tum.de/targo-benchmark/syn_train.tar.gz" style="color: #0065bd">compressed archive file</a> contains the following:
          </p>
          <ul>
            <li>
              <code>mesh_pose_dict/</code>: Each file is named by a unique <strong>scene ID</strong>, <strong>c / s</strong> (cluttered or single scene), and <strong>target ID</strong>. 
              For instance, <code>0006ab82ea3f4b8aad9445b27f45487b_s_1.npz</code> represents a scene with ID <code>0006ab82ea3f4b8aad9445b27f45487b</code>, a single scene, and the target object is the first object in the scene. The file contains the object meshes' file path and the poses of objects in the scene.
            </li>
            <li>
              <code>scenes/</code>: Same naming convention as the <code>mesh_pose_dict</code> folder. Each file contains the depth images, target masks, TSDF grids of the scene, and depth back-projected target points and occlusion levels.
            </li>
            <li>
              <code>grasps.csv</code>: This file lists the scene IDs of cluttered or single scenes along with their associated 6DoF grasp poses, grasp widths, and grasp labels (1 for success, 0 for failure).
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
          <div class="content has-text-centered">
            <h2>TARGO-Net Real-world Experiments in 2.5x Speed</h2>
          </div>
      </div>

      <!-- Create a single row with 3 columns for the videos -->
      <div class="columns is-centered">
        <!-- First video: TARGO-Net vs. GIGA -->
        <div class="column is-4">
          <div class="content has-text-centered">
            <h4 class="title is-4">TARGO-Net vs. GIGA</h4>
            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/2fMH2aHixMc?si=goQlmqKaSID_D4kQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>

        <!-- Second video: TARGO-Net Successful Grasps -->
        <div class="column is-4">
          <div class="content has-text-centered">
            <h4 class="title is-4">TARGO-Net Successful Grasps</h4>
            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/cy_XdFF7hks?si=Gevp98CbN_F5PIU2" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
    </div>
  </div>
</section>

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
